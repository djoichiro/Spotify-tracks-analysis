{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLuQ0KzzgEiC",
        "outputId": "75a3fcbd-531e-40fa-db06-dd513027c545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Подключение Google Диска (для доступа к файлу с датасетом)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек из PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, regexp_extract\n",
        "from pyspark.sql.types import DoubleType"
      ],
      "metadata": {
        "id": "dDOWLhpTgNWS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание сессии Spark\n",
        "spark # Загрузка CSV-файла с треками из Google Drive\n",
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\n",
        "    \"/content/drive/MyDrive/tracks.csv\"\n",
        ") = SparkSession.builder.appName(\"SpotifyTrends\").getOrCreate()"
      ],
      "metadata": {
        "id": "GXd9gmZngNsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b6cb44a2-a25a-4031-c6e1-682f44d57d8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/content/drive/MyDrive/tracks.csv.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-2254908697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Загрузка CSV-файла с треками из Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"/content/drive/MyDrive/tracks.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/drive/MyDrive/tracks.csv."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечение года из поля release_date, поддерживаются разные форматы:\n",
        "# yyyy, yyyy-MM, yyyy-MM-dd, dd/MM/yyyy\n",
        "df = df.withColumn(\n",
        "    \"release_year\",\n",
        "    when(col(\"release_date\").rlike(r\"^\\d{4}$\"),\n",
        "         col(\"release_date\").cast(\"int\"))\n",
        "    .when(col(\"release_date\").rlike(r\"^\\d{4}-\\d{2}$\"),\n",
        "          regexp_extract(col(\"release_date\"), r\"^(\\d{4})\", 1).cast(\"int\"))\n",
        "    .when(col(\"release_date\").rlike(r\"^\\d{2}/\\d{2}/\\d{4}$\"),\n",
        "          regexp_extract(col(\"release_date\"), r\"(\\d{4})$\", 1).cast(\"int\"))\n",
        "    .when(col(\"release_date\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}$\"),\n",
        "          regexp_extract(col(\"release_date\"), r\"^(\\d{4})\", 1).cast(\"int\"))\n",
        "    .otherwise(None)\n",
        ")"
      ],
      "metadata": {
        "id": "pwJ9_JSJgNx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фильтрация строк с корректным годом выпуска\n",
        "df = df.filter(col(\"release_year\").isNotNull())"
      ],
      "metadata": {
        "id": "o6r2V0_2gN0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оставляем только треки, выпущенные с 1920 года\n",
        "df = df.filter(col(\"release_year\") >= 1920)"
      ],
      "metadata": {
        "id": "3lvz-oyGgN3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисление десятилетия для каждого трека (например, 1987 → 1980)\n",
        "df = df.withColumn(\"decade\", (col(\"release_year\") / 10).cast(\"int\") * 10)"
      ],
      "metadata": {
        "id": "J5SoWSNagN5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Список аудиопараметров, которые будут анализироваться\n",
        "features = [\n",
        "    \"danceability\", \"energy\", \"loudness\", \"speechiness\",\n",
        "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"\n",
        "]"
      ],
      "metadata": {
        "id": "pZK3Y1fWgcI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Приведение каждого параметра к типу Double (для последующей агрегации)\n",
        "for feature in features:\n",
        "    df = df.withColumn(feature, col(feature).cast(DoubleType()))"
      ],
      "metadata": {
        "id": "GmNxlZyTgeiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Группировка по десятилетиям и вычисление среднего значения для каждого параметра\n",
        "agg_df = df.groupBy(\"decade\").avg(*features).orderBy(\"decade\")"
      ],
      "metadata": {
        "id": "fQb4VxGrgekO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение результата в CSV-файл (в одну партицию, с заголовками)\n",
        "agg_df.coalesce(1).write.option(\"header\", True).mode(\"overwrite\").csv(\"/content/drive/MyDrive/output/spotify_trends\")"
      ],
      "metadata": {
        "id": "xsaFDf8dgemk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод полученной таблицы в консоль\n",
        "agg_df.show()"
      ],
      "metadata": {
        "id": "Ky7Z38u6gcLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завершение сессии Spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "bIAl7P_Yghng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}